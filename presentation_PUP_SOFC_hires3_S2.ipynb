{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tomography reconstruction for PUP_FF_SOFC_hires3_S2\n",
    "\n",
    "## Objective\n",
    "Sub-micron resolution with high-energy X-ray tomography\n",
    "\n",
    "## Sample\n",
    "* SOFC sample (Cathode, Electrolyte, and Anode)\n",
    "* First complete/valid scan out of the total seven\n",
    "\n",
    "## Experiment apparatus\n",
    "* $\\omega \\in [-180^\\text{o}, 180^\\text{o}]$ with $\\dot{\\omega} = 0.1^\\text{o}$\n",
    "* image resolutoin: $0.2 \\mu m / \\text{pix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "* Using SVD based method to remove noises in the projection images (after background normalization)\n",
    "* Using image processing method adaptive histogram equalization ([CLAHE](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization)) to enhance the details in reconstruction results\n",
    "* Iterative method to compensate the horizontal sample jittering (locally) and drifting (globally)\n",
    "    * standard phase correlation based rotation center locator\n",
    "    * iterative global adjustment (IGA)\n",
    "    * iterative pairwise adjustment (IPA)\n",
    "* Various atttempt to compensate for the vertical sample jittering (locally) and drifting (globally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SVD-based noise reduction\n",
    "\n",
    "Singular value decompositionv (SVD) is a powerful tool that is commonly used for:\n",
    "* noise reduction for realtime image stream\n",
    "* lossy images compression \n",
    "* feature detection. \n",
    "\n",
    "In this section, the application of SVD based image enhancement for __tomography reconsutrction__ is investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def svd_enhance(img, eigen_cut=20):\n",
    "    U, S, V = np.linalg.svd(img, full_matrices=True)\n",
    "    eigen_cut = min(eigen_cut, U.shape[1], V.shape[0]) \n",
    "    return np.dot(U[:,:eigen_cut]*S[:eigen_cut], V[:eigen_cut,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> Simple example demonstrating eigen feature (eigenimg)\n",
    "\n",
    "![eigDemo](imgs/eignimg_2628.gif \"eig_400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVD enhanced projections with various n_eig\n",
    "\n",
    "Left= original image , middle= eigen space, right= reconstructed from reduced eigen space (SVD method)\n",
    "\n",
    "| `n_eig = 400`   | `n_eig = 300`    |\n",
    "| -----------   | -------------  |\n",
    "| ![eigMax400](imgs/img_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/img_eigMax300.gif \"eig_300\") | \n",
    "\n",
    "| `n_eig = 160`   | `n_eig = 80`    | \n",
    "| :-----------: |:-------------:|\n",
    "|![eigMax160](imgs/img_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/img_eigMax080.gif \"eig_80\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SVD enhanced projections with various n_eig\n",
    "\n",
    "Left= original image , middle= eigen space, right= reconstructed from reduced eigen space (SVD method)\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20` |\n",
    "| :-----:|:-----------: |\n",
    "| ![eigMax040](imgs/img_eigMax040.gif \"eig_40\") | ![eigMax20]( imgs/img_eigMax020.gif \"eig_20\") | \n",
    "\n",
    "| `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-------------:| :-----:|\n",
    "|![eigMax010](imgs/img_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/img_eigMax005.gif \"eig_5\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SVD enhanced projections with various n_eig\n",
    "\n",
    "* The first __20__ eigen-vectors are sufficient in capturing the main features in each image.\n",
    "* $F(I_{i,j}) = I_{i,j}^2$ is use to further suppress the noisy background. \n",
    "\n",
    "| `n_eig = 400`   | `n_eig = 300`    | `n_eig = 160`   | `n_eig = 80`    | \n",
    "| :-----------: |:-------------: | :-----------: |:-------------:|\n",
    "| ![eigMax400](imgs/img_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/img_eigMax300.gif \"eig_300\") | ![eigMax160](imgs/img_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/img_eigMax080.gif \"eig_80\") |\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20`    | `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-----:|:-----------: |:-------------:| :-----:|\n",
    "| ![eigMax040](imgs/img_eigMax040.gif \"eig_40\") | ![eigMax20]( imgs/img_eigMax020.gif \"eig_20\") | ![eigMax010](imgs/img_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/img_eigMax005.gif \"eig_5\") |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tomography reconstruction using SVD enhanced projections\n",
    "\n",
    "* Following the standard procedure, the rotation center of this data set can be found through phase correlation of the 180 degree pairs. \n",
    "* The significant horizontal jittering and drifing of the sample makes it difficult of acquire clear reconstruction results. Therefore, iterative global adjustment (IGA), a horizontal drift adjustment method, is used to __horizontally centering the sample__ from all __3601__ ($-180^\\text{o} \\to 180^\\text{o}$, $\\delta\\omega=0.1^\\text{o}$) images.\n",
    "\n",
    "> The detailed analysis of IGA will be covered in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With the enhanced and centered projection images, the tomograhy reconstruction can be eaisly done using existing toolkit (tomopy) with the command below\n",
    "\n",
    "```python\n",
    "recon = tomopy.recon(projs, thetas, \n",
    "                     center=rot_center, \n",
    "                     algorithm=recon_config['algorithm'],\n",
    "                     filter_name=recon_config['filter'],\n",
    "                    )\n",
    "```\n",
    "where the configuration of the reconsutrction is \n",
    "```python\n",
    "recon_config = {'algorithm': 'gridrec',\n",
    "                'filter'   : 'hann',\n",
    "               }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconstruction results\n",
    "\n",
    "| `n_eig = 400`   | `n_eig = 300`    | \n",
    "| :-----------: |:-------------: | \n",
    "| ![eigMax400](imgs/recon_conNeg_clipped_centered_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/recon_conNeg_clipped_centered_eigMax300.gif \"eig_300\") | \n",
    "\n",
    "| `n_eig = 160`   | `n_eig = 80`   |\n",
    "| :-----------:   |:-------------: |\n",
    "| ![eigMax160](imgs/recon_conNeg_clipped_centered_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/recon_conNeg_clipped_centered_eigMax080.gif \"eig_80\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reconstruction results\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20`    | \n",
    "| :-----:|:-----------: |\n",
    "| ![eigMax040](imgs/recon_conNeg_clipped_centered_eigMax040.gif \"eig_40\") | ![eigMax20](imgs/recon_conNeg_clipped_centered_eigMax020.gif \"eig_20\") | \n",
    "\n",
    "| `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-------------:| :-----:|\n",
    "| ![eigMax010](imgs/recon_conNeg_clipped_centered_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/recon_conNeg_clipped_centered_eigMax005.gif \"eig_5\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reconstruction results\n",
    "\n",
    "* The __more eigen features (vectors)__ used in the SVD enhancement, __the sharper__ the images. \n",
    "    * this effect is not linearly (__non-linearity__) depending no n_eig as the increase in sharpness plateaued quickly when n_eig passed __20__.\n",
    "\n",
    "| `n_eig = 400`   | `n_eig = 300`    | `n_eig = 160`   | `n_eig = 80`    | \n",
    "| :-----------: |:-------------: | :-----------: |:-------------:|\n",
    "| ![eigMax400](imgs/recon_conNeg_clipped_centered_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/recon_conNeg_clipped_centered_eigMax300.gif \"eig_300\") | ![eigMax160](imgs/recon_conNeg_clipped_centered_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/recon_conNeg_clipped_centered_eigMax080.gif \"eig_80\") |\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20`    | `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-----:|:-----------: |:-------------:| :-----:|\n",
    "| ![eigMax040](imgs/recon_conNeg_clipped_centered_eigMax040.gif \"eig_40\") | ![eigMax20](imgs/recon_conNeg_clipped_centered_eigMax020.gif \"eig_20\") | ![eigMax010](imgs/recon_conNeg_clipped_centered_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/recon_conNeg_clipped_centered_eigMax005.gif \"eig_5\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reconstruction results\n",
    "\n",
    "* The ring artifact (ripple features) are more prominent with larger n_eig.  \n",
    "    * when $n_\\text{eig}=5$, the ring artifacts almost disappearted.\n",
    "    * the preojction images reconstructed from the __first 5 eigen vectors__ looks very different from the original images (see previous sections), but the reconstruction results are __roughly the same__ as the other.\n",
    "\n",
    "| `n_eig = 400`   | `n_eig = 300`    | `n_eig = 160`   | `n_eig = 80`    | \n",
    "| :-----------: |:-------------: | :-----------: |:-------------:|\n",
    "| ![eigMax400](imgs/recon_conNeg_clipped_centered_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/recon_conNeg_clipped_centered_eigMax300.gif \"eig_300\") | ![eigMax160](imgs/recon_conNeg_clipped_centered_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/recon_conNeg_clipped_centered_eigMax080.gif \"eig_80\") |\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20`    | `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-----:|:-----------: |:-------------:| :-----:|\n",
    "| ![eigMax040](imgs/recon_conNeg_clipped_centered_eigMax040.gif \"eig_40\") | ![eigMax20](imgs/recon_conNeg_clipped_centered_eigMax020.gif \"eig_20\") | ![eigMax010](imgs/recon_conNeg_clipped_centered_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/recon_conNeg_clipped_centered_eigMax005.gif \"eig_5\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reconstruction results\n",
    "\n",
    "* A significant portion (~10%) of the pixels in the reconstruction images have negative values (natural outcome of tomopy)\n",
    "* The CDF distribution remains very steady, regardless of the number of eigen features used for reconstruction.\n",
    "    \n",
    "| `n_eig = 400`   | `n_eig = 300`    | `n_eig = 160`   | `n_eig = 80`    | \n",
    "| :-----------: |:-------------: | :-----------: |:-------------:|\n",
    "| ![eigMax400](imgs/recon_conNeg_clipped_centered_eigMax400.gif \"eig_400\") | ![eigMax300](imgs/recon_conNeg_clipped_centered_eigMax300.gif \"eig_300\") | ![eigMax160](imgs/recon_conNeg_clipped_centered_eigMax160.gif \"eig_160\") | ![eigMax080](imgs/recon_conNeg_clipped_centered_eigMax080.gif \"eig_80\") |\n",
    "\n",
    "| `n_eig = 40`  | `n_eig = 20`    | `n_eig = 10`    | `n_eig = 5`  |\n",
    "| :-----:|:-----------: |:-------------:| :-----:|\n",
    "| ![eigMax040](imgs/recon_conNeg_clipped_centered_eigMax040.gif \"eig_40\") | ![eigMax20](imgs/recon_conNeg_clipped_centered_eigMax020.gif \"eig_20\") | ![eigMax010](imgs/recon_conNeg_clipped_centered_eigMax010.gif \"eig_10\") | ![eigMax005](imgs/recon_conNeg_clipped_centered_eigMax005.gif \"eig_5\") |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary (SVD-based noise reduction)\n",
    "\n",
    "Overall, the SVD based denoising method proves to be efficient in removing the unwanted background noises in the normalized images.\n",
    "\n",
    "* Pros\n",
    "    * efficient in removing unwanted noises in the normilzed images\n",
    "    * easy to implement\n",
    "    * only need first 20 eigen vectors\n",
    "* Cons\n",
    "    * fine details (pixel level) might lost in the process\n",
    "    * high computation cost\n",
    "    * might introduce artifacts in the final results\n",
    "\n",
    "> NOTE:\n",
    "The SVD based enhancement also has very little effect for the sample jittering/drifting adjustment, the details of which are covered in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Enhance reconstruction results with adaptive histogram equilization\n",
    "\n",
    "The tomography reconstruction results from high energy xray diffraction often has low contrast, making it difficult to spot the important features through visual inspection.\n",
    "To overcome this issue, adaptive histogram equilization ([CLAHE](https://en.wikipedia.org/wiki/Adaptive_histogram_equalization)) is used to bring out the details in the reconstruction results.\n",
    "An __interactive__ example is provided in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoCLAHE.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aee7b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='docs/demoCLAHE.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__NOTE__  \n",
    "several features about CLAHE need to be pointed out here:\n",
    "\n",
    "* CLAHE does not add _new_ features, it only amplify features based on local histogram\n",
    "* CLAHE does not remove artifacts.\n",
    "    * It might actually amplify the artifacts\n",
    "* CLAHE can be computational expensive\n",
    "    * The CLAHE performed here is using the CLAHE function provided by ImageJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Horizontal sample jittering and drifting\n",
    "\n",
    "As mentioned in previous section, significant amount of sample jittering (locally) and drifting (globally) were found along the horizontal axis. \n",
    "In other words, the rotation center for each image are not necessearily correlated anymore.\n",
    "Therefore, it is necesary to properly align samples from different images ($\\omega$) such that a universal rotation center can be defined for the reconstruction process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To this end, two different method are proposed here:\n",
    "\n",
    "* iterative global adjustment (IGA)\n",
    "    * calcuate the rotation center ($y_{rc}^\\omega$) of each pair image ($\\Delta\\omega = 180^\\text{o}$)\n",
    "    * find the average rotatio center $\\bar{y}_{rc}$ \n",
    "    * move the rotation center of each pair to the center column using $\\bar{y}_{rc}$\n",
    "    * calculate new average rotatio center $y_{rc}'$\n",
    "    * repeat until $y_{rc}$ converges\n",
    "* iterative pairwise adjustment (IPA)\n",
    "    * calcuate the rotation center ($y_{rc}^\\omega$) of each pair image ($\\Delta\\omega = 180^\\text{o}$)\n",
    "    * move rotation center of each image to the center column using $y_{rc}^\\omega$\n",
    "    * calculate average rotatio center $y_{rc}'$\n",
    "    * repeat until $y_{rc}$ converges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Profiling the horizontal jittering\n",
    "\n",
    "Using phase correlation on image pairs that are $180^\\text{o}$ away along $\\omega$-axis, individual rotation centers $y_{rc}^\\omega$ can be located for all images, the distribution of which can be used to evaluate the horizontal misalignment for the projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/rotcnt_stats.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10874f518>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wIFrame(src='imgs/rotcnt_stats.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The distribution shows \n",
    "* large variance of $y_c$ in raw data (~20 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/rotcnt_stats.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10874f390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/rotcnt_stats.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The distribution shows \n",
    "* IGA brings the average rotation center ($\\bar{y}_{rc}^\\omega$) down to the image column center (250).\n",
    "    * this has little effect of the variance of $y_{rc}^\\omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/rotcnt_stats.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aee208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/rotcnt_stats.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The distribution above shows\n",
    "* IPA brings almost all the rotation centers to 250, except for six $\\omega$s (3 pairs).\n",
    "    * Further investigation reveals that these three _uncorrectable_ pairs contains at least one corrupted image, which need to be exculded.\n",
    "    * IPA also serves as an image corruption detector as its response to corrupted images is drastically different from the proper images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"750\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/rotcnt_stats.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aeea90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/rotcnt_stats.pdf', width=750, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Original v.s. IPA\n",
    "\n",
    "* Reconstruction results for original case and IGA case are both enhanced with SVD (first 20 eigen vectors) and CLAHE  \n",
    "* The side view is the central cross slice generated using ImageJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IGA (top view, XZ in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIGA.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b09048>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IGA (top view, XZ in aps)\")\n",
    "IFrame(src='docs/demoIGA.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IGA (side view, XY in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIGA_YZ.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b09668>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IGA (side view, XY in aps)\")\n",
    "IFrame(src='docs/demoIGA_YZ.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IGA (side view, YZ in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"400\"\n",
       "            src=\"docs/demoIGA_XZ.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b091d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IGA (side view, YZ in aps)\")\n",
    "IFrame(src='docs/demoIGA_XZ.html', width=550, height=400)w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Original v.s. IPA\n",
    "\n",
    "* The side views indicate that the proposed horizontal alignment can significantly imporove the reconstructed geometry as well as reducing the ambient noise from the reconstruction process.  \n",
    "    * geometrical distortion of the sample is still presetn even after the IPA based horizontal correction, suggesting that there are other factors that need to be addressed in order to further improve the reconstruction quality.\n",
    "\n",
    "* The side view is taken at the center (central cross-slice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IPA (top view, XZ in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIPA.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b090b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IPA (top view, XZ in aps)\")\n",
    "IFrame(src='docs/demoIPA.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IPA (side view, XY in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIPA_YZ.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b09278>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IPA (side view, XY in aps)\")\n",
    "IFrame(src='docs/demoIPA_YZ.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original v.s. IPA (side view, YZ in aps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"400\"\n",
       "            src=\"docs/demoIPA_XZ.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b092e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Original v.s. IPA (side view, YZ in aps)\")\n",
    "IFrame(src='docs/demoIPA_XZ.html', width=550, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compensate for vertical sample jittering/drifting\n",
    "\n",
    "One possible cause of the persistent distortion in the reconstructed images (post horizontal alignment) could be the sample jittering along the image vertical direction.  However, there is no straightforward way to compensate for the vertical sample jittering (locally) and drifting (globally) due to lack of a common reference feature among different images. \n",
    "\n",
    "> For the horizontal alignment, the rotation center, which should be the same for all images, serves as an intrinsic reference feature.  Therefore, it is possible to improve the horizontal alignment by moving the rotation center of each $180^\\text{o}$ pair to a common location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The methods proposed in this section assume that the vertial offset between neighboring images (along $\\omega$) are small but detectable.\n",
    "\n",
    "* Nearest neighbor phase correlation method:  \n",
    "Walking along $\\omega$ direction, each image is vertically alinged with its previous neighbor using phase correlation.\n",
    "* Cumulative neighbor phase correaltion method:  \n",
    "Similar to the previous method, the discrete vertical shift is calcualte by performing phase correaltion on each image with its immediate previous neighbor. \n",
    "After collecting all discrete vertical shift, the cumulative vertical shift is calculated with rolling sum $$ \\Delta_v^{i} = \\sum_{\\omega=1}^{i} \\delta_v^{\\omega},  $$ which is then applied to each image to compensate for the vertical drifting.\n",
    "* Pairwise method:  \n",
    "Similar to the horizontal alignment process, the vertical offset bewteen the $180^\\text{o}$ pair is calcuated using phase correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> * Due to the small magnitude of vertical shift bewteen neighboring images, an up-sampling is used to achieve 0.01 pixel resolution.  However, it is difficult to tell whether this up-sampping (100x) would be physically meaningful as no existing published work are dedicated for this topic.  \n",
    "> * The vertial shift correction are only performed for the shift that is larger than the prescribed tolerance (0.01 pixel).  This is true for all three methods proposed in this section.  \n",
    "> * Corrupted images detected from the horizontal alignment step (see previous section) are excluded from the vertical alignment process to avoid introducing new error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample vertical jittering prfile\n",
    "\n",
    "The figure demonstrates the sample vertical jittering with respect to $\\omega$ (left) as well as the assocaited cumulative distribution function (CDF, right). \n",
    "The dark green shade in both figures represents the tolerance limit ($\\pm 0.01$ pixels), and the light green shade denotes the limit of $\\pm 0.1$ pixels.\n",
    "\n",
    "The green line ($\\delta_v$) represents the local vertical jittering identified through neighboring phase correlation.\n",
    "As shown in the left figure, the majority of $\\delta_v$ are within 0.1 pixel, fluctuating around zero.\n",
    "\n",
    "The cumulate vertical shift (orange solid and dashed green) are the rolling sum described above.   The dashed green line are the one used for vertical shift adjustment as it exclude local vertical jittering that is below the tolerance use in upsamppling (0.01 pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/verticalJitterProfile_0asRef.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b092b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/verticalJitterProfile_0asRef.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nearest neighbor phase correlation method\n",
    "\n",
    "After the adjustment, the vertical jittering is worsened by nearly a factor of two.  Indicating that the vertical offset calculated from upsamplled neighboring images are not suitable for adjusting the vertical jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/verticalJitterProfile_0asRef_pstAdjust_NearetsNeighbor.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aee0f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/verticalJitterProfile_0asRef_pstAdjust_NearetsNeighbor.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Very little difference due to the vertical adjustment can be observed from the top view (below) and side views (not shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top view, XZ in aps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIPA_vn.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b09160>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"top view, XZ in aps\")\n",
    "IFrame(src='docs/demoIPA_vn.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cumulative neighbor phase correaltion method\n",
    "\n",
    "Similar to previous method, no significant improvement can be found after applying the vertical adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/verticalJitterProfile_0asRef_pstAdjust_cumulativeNearetsNeighbor.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aee908>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/verticalJitterProfile_0asRef_pstAdjust_cumulativeNearetsNeighbor.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top view, XZ in aps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIPA_vcn.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b095c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"top view, XZ in aps\")\n",
    "IFrame(src='docs/demoIPA_vcn.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pairwise method\n",
    "\n",
    "Similar to previous results, the benefits of applying this vertical adjustment is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"850\"\n",
       "            height=\"500\"\n",
       "            src=\"imgs/verticalJitterProfile_0asRef_pstAdjust_pairwise.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109aee8d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='imgs/verticalJitterProfile_0asRef_pstAdjust_pairwise.pdf', width=850, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top view, XZ in aps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"500\"\n",
       "            src=\"docs/demoIPA_vp.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x109b09630>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"top view, XZ in aps\")\n",
    "IFrame(src='docs/demoIPA_vp.html', width=550, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary (vertical alignment)\n",
    "Althogh the vertical jittering (locally) are always worsened after applying the vertical adjustment, there is almost no visible effect on the reonstruction results.\n",
    "Perhaps, the subpixel local vertical gittering does not have any noticable effect on the final reconstruction results.\n",
    "In other words, the vertical alignment in the current data set is not the cause of the remaining distortion observed in previous section (after horizontal alignment)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
